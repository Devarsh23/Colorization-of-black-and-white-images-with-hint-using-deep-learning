{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import shutil\n# src_path = '/kaggle/input/refined-7-draft-45/PaintsTensorFlowDraftNet_50.h5'\n# dst_path = '/kaggle/working/PaintsTensorFlowDraftNet_50.h5'\n\n# dest = shutil.copyfile(src_path, dst_path) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import cv2\n# imagePath = '/kaggle/input/colorization-to-sketch-ru/real-img'\n# for img in os.listdir(imagePath):\n#     image = cv2.imread(imagePath+'/'+img)\n#     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#     (thresh, blackAndWhiteImage) = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n#     path = '/kaggle/working/train_sketch/'+img\n#     cv2.imwrite(path, blackAndWhiteImage)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**converting color image to sketch**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loadEpochs = 10\nimport tensorflow as tf\nimport cv2\nfrom glob import glob\n\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\ntf.compat.v1.enable_eager_execution(config=config)\n\nfrom tqdm import tqdm\n\n# edit by your path\n__SAVED_MODEL_PATH__ = '/kaggle/input/draft-50final/PaintsTensorFlowDraftNet_50.h5'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hyperparameters.py\nbatch_steps = 0\n\ngf_dim = 64\ndf_dim = 64\nc_dim = 3\n\nlr = 1e-5\nbeta1 = 0.9\nbeta2 = 0.99\n\nl1_scaling = 100\nl2_scaling = 10\n\nepoch = 2\nbatch_size = 4\n\nlog_interval = 10\nsampling_interval = 200\nsave_interval = 4000\n\ntrain_image_datasets_path = \"/kaggle/input/colorization-to-sketch-ru/real-img/*\"\ntrain_line_datasets_path = \"/kaggle/input/colorization-to-sketch-ru/sketch-img/*\"\ntest_image_datasets_path = \"/kaggle/input/colorization-to-sketch-ru/real-img-test/*\"\ntest_line_datasets_path = \"/kaggle/input/colorization-to-sketch-ru/sketch-img-test/*\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# utils.py\ndef get_line(imgs):\n    def img_liner(img):\n        k = 3\n        kernal = np.ones((k, k), dtype=np.uint8)\n        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        dilated = cv2.dilate(gray, kernal, iterations=1)\n        diff = cv2.absdiff(dilated, gray)\n        img = 255 - diff\n        return img\n\n    lines = np.array([img_liner(l) for l in imgs])\n    return np.expand_dims(lines, 3)\n\n\ndef convert2f32(img):\n    img = img.astype(np.float32)\n    return (img / 127.5) - 1.0\n\n\ndef convert2uint8(img):\n    img = (img + 1) * 127.5\n    return img.astype(np.uint8)\n\n\ndef convertRGB(imgs):\n    imgs = np.asarray(imgs, np.uint8)\n    return np.array([cv2.cvtColor(img, cv2.COLOR_YUV2RGB) for img in imgs])\n\n\ndef mkdir(path):\n    try:\n        os.mkdir(path)\n    except FileExistsError:\n        pass\n\n\ndef initdir(model_name):\n    base = os.path.join(\"/kaggle/working/\", model_name)\n    mkdir(base)\n    mkdir(os.path.join(base, \"board\"))\n    mkdir(os.path.join(base, \"image\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SubNet.py\n__INITIALIZER__ = tf.random_normal_initializer(0., 0.02)\n__MOMENTUM__ = 0.9\n__EPSILON__ = 1e-5\n\n\ndef res_net_block_v2(inputs, filters):\n    with tf.name_scope(\"ResNetBlock\"):\n        shortcut = inputs\n        tensor = tf.keras.layers.BatchNormalization()(inputs)\n        tensor = tf.keras.layers.ReLU()(tensor)\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"SAME\")(tensor)\n\n        tensor = tf.keras.layers.BatchNormalization()(tensor)\n        tensor = tf.keras.layers.ReLU()(tensor)\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"SAME\")(tensor)\n        tensor = tf.keras.layers.add([shortcut, tensor])\n    return tensor\n\n\ndef GenConvBlock(inputs, filters, k, s, res_net_block=True, name=\"GenConvBlock\"):\n    filters = int(filters)\n    with tf.name_scope(name):\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=k, strides=s, use_bias=False,\n                                        padding=\"SAME\", kernel_initializer=__INITIALIZER__)(inputs)\n\n        if res_net_block:\n            tensor = res_net_block_v2(tensor, filters)\n        else:\n            tensor = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)(tensor)\n            tensor = tf.keras.layers.LeakyReLU()(tensor)\n\n        return tensor\n\n\ndef GenUpConvBlock(inputs_a, inputs_b, filters, k, s, res_net_block=True, name=\"GenUpConvBlock\"):\n    filters = int(filters)\n    with tf.name_scope(name):\n        tensor = tf.keras.layers.Concatenate(3)([inputs_a, inputs_b])\n        tensor = tf.keras.layers.Conv2DTranspose(filters=filters, kernel_size=k, strides=s, use_bias=False,\n                                                 padding=\"SAME\", kernel_initializer=__INITIALIZER__)(tensor)\n\n        if res_net_block:\n            tensor = res_net_block_v2(tensor, filters)\n        else:\n            tensor = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)(tensor)\n            tensor = tf.keras.layers.ReLU()(tensor)\n\n        return tensor\n\n\nclass DisConvBlock(tf.keras.Model):\n    def __init__(self, filters, k, s, apply_bat_norm=True, name=None):\n        super(DisConvBlock, self).__init__(name=name)\n        initializer = tf.random_normal_initializer(0., 0.02)\n        filters = int(filters)\n        self.apply_bat_norm = apply_bat_norm\n        self.conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=k, strides=s,\n                                           padding=\"SAME\", kernel_initializer=initializer)\n        if self.apply_bat_norm:\n            self.bn = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)\n\n        self.act = tf.keras.layers.LeakyReLU(alpha=0.2)\n\n    def call(self, inputs, training):\n        tensor = self.conv(inputs)\n\n        if self.apply_bat_norm:\n            tensor = self.bn(tensor, training=training)\n\n        tensor = self.act(tensor)\n        return tensor\n\n\ndef tf_int_round(num):\n    return tf.cast(tf.round(num), dtype=tf.int32)\n\n\nclass resize_layer(tf.keras.layers.Layer):\n    def __init__(self, size=(512, 512), **kwargs, ):\n        super(resize_layer, self).__init__(**kwargs)\n        (self.height, self.width) = size\n\n    def build(self, input_shape):\n        super(resize_layer, self).build(input_shape)\n\n    def call(self, x, method=\"nearest\"):\n        height = 512\n        width = 512\n\n        if method == \"nearest\":\n            return tf.image.resize_nearest_neighbor(x, size=(height, width))\n        elif method == \"bicubic\":\n            return tf.image.resize_bicubic(x, size=(height, width))\n        elif method == \"bilinear\":\n            return tf.image.resize_bilinear(x, size=(height, width))\n\n    def get_output_shape_for(self, input_shape):\n        return (self.input_shape[0], 512, 512, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PaintsTensorflow\ndef Generator(inputs_size=None, res_net_block=True, name=\"PaintsTensorFlow\"):\n    inputs_line = tf.keras.Input(shape=[inputs_size, inputs_size, 1], dtype=tf.float32, name=\"inputs_line\")\n    inputs_hint = tf.keras.Input(shape=[inputs_size, inputs_size, 3], dtype=tf.float32, name=\"inputs_hint\")\n    tensor = tf.keras.layers.Concatenate(3)([inputs_line, inputs_hint])\n\n    e0 = GenConvBlock(tensor,gf_dim / 2, 3, 1, res_net_block=res_net_block, name=\"E0\")  # 64\n    e1 = GenConvBlock(e0, gf_dim * 1, 4, 2, res_net_block=res_net_block, name=\"E1\")\n    e2 = GenConvBlock(e1, gf_dim * 1, 3, 1, res_net_block=res_net_block, name=\"E2\")\n    e3 = GenConvBlock(e2, gf_dim * 2, 4, 2, res_net_block=res_net_block, name=\"E3\")\n    e4 = GenConvBlock(e3, gf_dim * 2, 3, 1, res_net_block=res_net_block, name=\"E4\")\n    e5 = GenConvBlock(e4, gf_dim * 4, 4, 2, res_net_block=res_net_block, name=\"E5\")\n    e6 = GenConvBlock(e5, gf_dim * 4, 3, 1, res_net_block=res_net_block, name=\"E6\")\n    e7 = GenConvBlock(e6, gf_dim * 8, 4, 2, res_net_block=res_net_block, name=\"E7\")\n    e8 = GenConvBlock(e7, gf_dim * 8, 3, 1, res_net_block=res_net_block, name=\"E8\")\n\n    d8 = GenUpConvBlock(e7, e8, gf_dim * 8, 4, 2, res_net_block=res_net_block, name=\"D8\")\n    d7 = GenConvBlock(d8, gf_dim * 4, 3, 1, res_net_block=res_net_block, name=\"D7\")\n    d6 = GenUpConvBlock(e6, d7, gf_dim * 4, 4, 2, res_net_block=res_net_block, name=\"D6\")\n    d5 = GenConvBlock(d6, gf_dim * 2, 3, 1, res_net_block=res_net_block, name=\"D5\")\n    d4 = GenUpConvBlock(e4, d5, gf_dim * 2, 4, 2, res_net_block=res_net_block, name=\"D4\")\n    d3 = GenConvBlock(d4, gf_dim * 1, 3, 1, res_net_block=res_net_block, name=\"D3\")\n    d2 = GenUpConvBlock(e2, d3, gf_dim * 1, 4, 2, res_net_block=res_net_block, name=\"D2\")\n    d1 = GenConvBlock(d2, gf_dim / 2, 3, 1, res_net_block=res_net_block, name=\"D1\")\n\n    tensor = tf.keras.layers.Concatenate(3)([e0, d1])\n    outputs = tf.keras.layers.Conv2D(c_dim, kernel_size=3, strides=1, padding=\"SAME\",\n                                     use_bias=True, name=\"output\", activation=tf.nn.tanh,\n                                     kernel_initializer=tf.random_normal_initializer(0., 0.02))(tensor)\n\n    inputs = [inputs_line, inputs_hint]\n    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n    return model\n\nclass Discriminator(tf.keras.Model):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.h0 = DisConvBlock(df_dim / 2, 4, 2)\n        self.h1 = DisConvBlock(df_dim / 2, 3, 1)\n        self.h2 = DisConvBlock(df_dim * 1, 4, 2)\n        self.h3 = DisConvBlock(df_dim * 1, 3, 1)\n        self.h4 = DisConvBlock(df_dim * 2, 4, 2)\n        self.h5 = DisConvBlock(df_dim * 2, 3, 1)\n        self.h6 = DisConvBlock(df_dim * 4, 4, 2)\n        self.flatten = tf.keras.layers.Flatten()\n        self.last = tf.keras.layers.Dense(1, activation=\"linear\", kernel_initializer=tf.initializers.he_normal())\n\n#     @tf.contrib.eager.defun\n    def call(self, inputs, training):\n        tensor = self.h0(inputs, training)\n        tensor = self.h1(tensor, training)\n        tensor = self.h2(tensor, training)\n        tensor = self.h3(tensor, training)\n        tensor = self.h4(tensor, training)\n        tensor = self.h5(tensor, training)\n        tensor = self.h6(tensor, training)\n        tensor = self.flatten(tensor)  # (?,16384)\n        tensor = self.last(tensor)\n        return tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Datasets.py\nimport cv2\nclass Datasets:\n    def __init__(self, prefetch=-1, batch_size=1, shuffle=False):\n        self.prefetch = prefetch\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        \n    def get_image_and_line(self):\n        image = glob(train_image_datasets_path)\n        image.sort()\n        line = glob(train_line_datasets_path)\n        line.sort()\n        return image, line\n        \n    def _next(self, image, line):   \n        return self.buildDataSets(image, line)\n        \n  \n\n    def _preprocess(self, image, line, training = 'True'):\n        if training == 'True':\n            if np.random.rand() < 0.5:\n                image = cv2.flip(np.float32(image), 0)\n                line = cv2.flip(np.float32(line), 0)\n#                 line = np.expand_dims(line, 3)\n\n            if np.random.rand() < 0.5:\n                image = cv2.flip(np.float32(image), 1)\n                line = cv2.flip(np.float32(line), 1)\n#                 line = np.expand_dims(line, 3)\n\n        return image, line, self._buildHint_resize(image)\n\n    def _buildHint_resize(self, image):\n        random = np.random.rand\n        hint = np.ones_like(image)\n        hint += 1\n        leak_count = np.random.randint(16, 120)\n\n        if random() < 0.4:\n            leak_count = 0\n        elif random() < 0.7:\n            leak_count = np.random.randint(2, 16)\n\n        # leak position\n        x = np.random.randint(1, image.shape[0] - 1, leak_count)\n        y = np.random.randint(1, image.shape[1] - 1, leak_count)\n\n        def paintCel(i):\n            color = image[x[i]][y[i]]\n            hint[x[i]][y[i]] = color\n\n            if random() > 0.5:\n                hint[x[i]][y[i] + 1] = color\n                hint[x[i]][y[i] - 1] = color\n\n            if random() > 0.5:\n                hint[x[i] + 1][y[i]] = color\n                hint[x[i] - 1][y[i]] = color\n\n        for i in range(leak_count):\n            paintCel(i)\n\n        return hint\n\n    def convert2float(self, image):\n        image = tf.cast(image, tf.float32)\n        image = (image / 127.5) \n        return image\n\n    def __line_threshold(self, line):\n        if np.random.rand() < 0.3:\n            line = np.reshape(line, newshape=(512, 512))\n            _, line = cv2.threshold(line, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            line = np.reshape(line, newshape=(512, 512, 1))\n        return line\n\n    def loadImage(self, imagePath, linePath, isTrain='True'):\n#         print (imagePath)\n        image = tf.io.read_file(imagePath)\n        image = tf.image.decode_jpeg(image, channels=3)\n\n        line = tf.io.read_file(linePath)\n        line = tf.image.decode_jpeg(line, channels=1)\n\n        image = tf.image.resize(image, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        \n#         plt.imshow(image)\n        line = tf.image.resize(line, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        image = self.convert2float(image)\n        line = self.convert2float(line)\n\n        image, line, hint = tf.py_function(self._preprocess,\n                                       [np.float32(image), np.float32(line), str(isTrain)],\n                                       [tf.float32, tf.float32, tf.float32])\n    \n\n        return image, line, hint\n\n    def buildDataSets(self, image, line):\n        def build_dataSets(image, line, shuffle=False, isTrain=False):\n\n            if shuffle is False and isTrain is False:\n                image.reverse()\n                line.reverse()\n\n            batch_steps = int(3000 / self.batch_size)\n            datasets = tf.data.Dataset.from_tensor_slices((image, line))\n\n            image_data = []\n            line_data = []\n            hint_data = []\n            line128_data = []\n            hint128_data = []\n            for ele in datasets:\n                p, q, x, y ,z  = self.loadImage(ele[0], ele[1], str(isTrain))\n#                 x, y ,z  = self.loadImage(ele[0], ele[1], str(isTrain))\n                #line_128, hint_128, image, line, hint\n                line128_data.append(p)\n                hint128_data.append(q)\n                image_data.append(x)                \n                line_data.append(y)\n                hint_data.append(z)\n                del (p)\n                del (q)\n                del (x)\n                del (y)\n                del (z)\n\n            del(datasets)\n            del (line)\n            del(image)\n            return line128_data, hint128_data, image_data, line_data, hint_data\n#             return image_data, line_data, hint_data\n\n#         testDatasets = build_dataSets(image, line, shuffle=False, isTrain=False)\n\n        trainDatasets = build_dataSets(image, line, shuffle=False, isTrain=True)\n        return trainDatasets\n\n#         return trainDatasets, testDatasets\n\nclass Datasets_512(Datasets):\n    def __init__(self ,batch_size):\n        self.batch_size = batch_size\n        super().__init__(self, batch_size = self.batch_size)\n        \n    def get_image_and_line(self):\n        image = glob(train_image_datasets_path)\n        image.sort()\n        line = glob(train_line_datasets_path)\n        line.sort()\n        return image, line\n        \n    def _next(self, image, line):   \n        return self.buildDataSets(image, line)\n        \n    def _flip(self, image, line, training):\n        if training:\n            if np.random.rand() < 0.5:\n                image = cv2.flip(image, 0)\n                line = cv2.flip(line, 0)\n#                 line = np.expand_dims(line, 3)\n\n            if np.random.rand() < 0.5:\n                image = cv2.flip(image, 1)\n                line = cv2.flip(line, 1)\n#                 line = np.expand_dims(line, 3)\n\n        return image, line\n\n    def _buildHint(self, image):\n        random = np.random.rand\n        hint = np.ones_like(image)\n        hint += 1\n        leak_count = np.random.randint(16, 128)\n\n        # leak position\n        x = np.random.randint(1, image.shape[0] - 1, leak_count)\n        y = np.random.randint(1, image.shape[1] - 1, leak_count)\n\n        def paintCel(i):\n            color = image[x[i]][y[i]]\n            hint[x[i]][y[i]] = color\n\n            if random() > 0.5:\n                hint[x[i]][y[i] + 1] = color\n                hint[x[i]][y[i] - 1] = color\n\n            if random() > 0.5:\n                hint[x[i] + 1][y[i]] = color\n                hint[x[i] - 1][y[i]] = color\n\n        for i in range(leak_count):\n            paintCel(i)\n        return hint\n\n    def loadImage(self, imagePath, linePath, train):\n#         print (imagePath)\n        image = tf.io.read_file(imagePath)\n        image = tf.image.decode_jpeg(image, channels=3)\n        line = tf.io.read_file(linePath)\n        line = tf.image.decode_jpeg(line, channels=1)\n        image = tf.image.resize(image, (512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        line = tf.image.resize(line, (512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        image_128 = tf.image.resize(image, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        line_128 = tf.image.resize(line, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        image = self.convert2float(image)\n        line = self.convert2float(line)\n        image_128 = self.convert2float(image_128)\n        line_128 = self.convert2float(line_128)\n\n        hint_128 = tf.py_function(self._buildHint,\n                                  [image_128],\n                                  tf.float32)\n\n        hint_128.set_shape(shape=image_128.shape)\n        hint = tf.image.resize(hint_128, (512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        return line_128, hint_128, image, line, hint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/refined-7-draft-45/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PaintsTensorflowTraining\nimport time\nclass PaintsTensorFlowTrain:\n    def __init__(self, model_name=\"PaintsTensorFlow\"):\n        self.data_sets = Datasets_512(batch_size=750)\n        self.model_name = \"{}\".format(model_name)\n        initdir(self.model_name)\n\n        self.global_steps = tf.compat.v1.train.get_or_create_global_step()\n        self.epochs = tf.Variable(0, trainable=False, dtype=tf.int32)\n\n        self.saved_refined = '/kaggle/input/refined-7-draft-45/PaintsTensorFlow_refined_30.h5' #./PaintsTensorFlow_refined_11.h5\n        self.generator_128 =  tf.keras.models.load_model(__SAVED_MODEL_PATH__)\n        self.generator_512 = tf.keras.models.load_model(self.saved_refined)\n#         self.generator_512 = Generator(res_net_block=False)\n        self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n\n\n    def __loss(self, output, target):\n        loss = tf.reduce_mean(tf.abs(target - output))\n        return loss\n\n    def __pred_image(self, model, image, line, hint, draft, epoch=None):\n        gs = self.global_steps.numpy()\n        predImage = model.predict([line, draft])\n\n\n        if epoch is not None:\n            loss = self.__loss(predImage, image)\n\n            loss = \"{:0.05f}\".format(loss).zfill(7)\n            print(\"Epoch:{} GS:{} LOSS:{}\".format(epoch, self.global_steps.numpy(), loss))\n\n\n        hint = np.array(hint)\n        hint[hint > 1] = 1\n\n        lineImage = np.concatenate([line, line, line], -1)\n        save_img = np.concatenate([lineImage, hint, draft, predImage, image], 1)\n        save_img = utils.convert2uint8(save_img)\n        tl.visualize.save_images(save_img, [1, save_img.shape[0]], file_name)\n\n    def load_caffee(self):\n        print(\"[INFO] loading model...\")\n        self.net = cv2.dnn.readNetFromCaffe(\"/kaggle/input/reuirements/colorization_deploy_v2.prototxt\", \"/kaggle/input/reuirements/colorization_release_v2.caffemodel\")\n        self.pts = np.load(\"/kaggle/input/reuirements/pts_in_hull.npy\")\n        \n    def pred_caffee(self, line_128):\n        class8 = self.net.getLayerId(\"class8_ab\")\n        conv8 = self.net.getLayerId(\"conv8_313_rh\")\n        self.pts = self.pts.transpose().reshape(2, 313, 1, 1)\n        self.net.getLayer(class8).blobs = [self.pts.astype(\"float32\")]\n        self.net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]\n        \n        pred_img = []\n        for i in range(0,4):\n            print (line_128[i])\n            image = cv2.imread(line_128[i])\n            plt.imshow(image)\n            scaled = image.astype(\"float32\") / 255.0\n#             lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)\n            resized = cv2.resize(np.float32(scaled), (224, 224))\n            L = cv2.split(resized)[0]\n            L -= 50\n            self.net.setInput(cv2.dnn.blobFromImage(L))\n            ab = self.net.forward()[0, :, :, :].transpose((1, 2, 0))\n            ab = cv2.resize(ab, (image.shape[1], image.shape[0]))\n            L = cv2.split(np.float32(scaled))[0]\n            colorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)\n\n            colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n            colorized = np.clip(colorized, 0, 1)\n            colorized = (255 * colorized).astype(\"uint8\")\n            colorized = tf.image.resize(colorized, size=(512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n            pred_img.append(colorized)\n        return pred_img\n        \n        \n        \n        \n        \n    def __draft_image(self, line_128, hint_128):\n        draft = self.generator_128.predict([line_128, hint_128])\n#         print (draft.shape\n        draft = tf.image.resize(draft, size=(512, 512),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        return draft\n    \n    \n    \n    def fast_fetch(self,size, Traindata):        \n        if (size[3]==3):\n            x=np.zeros(size)\n            for i in range(0,4):\n                t = Traindata[i]\n                x[i] = np.asarray(t, np.float32)        \n            return x\n        elif (size[3] ==1):\n            x=np.zeros(size)\n            for i in range(4):\n                t = Traindata[i]\n                x[i,:,:,0] = np.asarray(t,np.float32).reshape(size[1],size[2])\n            return x\n          \n    \n    \n\n    def training(self, loadEpochs=0):\n\n        images, lines = self.data_sets.get_image_and_line()\n\n        for epoch in range(loadEpochs):\n\n            print ('epoch {}'.format(epoch))\n            print(\"GS: \", self.global_steps.numpy())\n            for batchs in range(750):\n                \n                print (batchs , end = '\\r')\n                trainData = self.data_sets._next(images[(batchs*4):(batchs*4)+4], lines[(batchs*4):(batchs*4)+4])\n    \n#                 prediction = self.pred_caffee(images[(batchs*4):(batchs*4)+4])\n#                 draft = tf.convert_to_tensor(fast_fetch((4,512,512,3), prediction), dtype=tf.float32, dtype_hint=None, name=None)\n#                 return prediction\n                image = tf.convert_to_tensor(self.fast_fetch((4,512,512,3), trainData[2]), dtype=tf.float32, dtype_hint=None, name=None)        \n                line = tf.convert_to_tensor(self.fast_fetch((4,512,512,1), trainData[3]), dtype=tf.float32, dtype_hint=None, name=None)\n                hint = tf.convert_to_tensor(self.fast_fetch((4,512,512,3), trainData[4]), dtype=tf.float32, dtype_hint=None, name=None)\n                line_128 = tf.convert_to_tensor(self.fast_fetch((4,128,128,1), trainData[0]), dtype=tf.float32, dtype_hint=None, name=None)\n                hint_128 = tf.convert_to_tensor(self.fast_fetch((4,128,128,3), trainData[1]), dtype=tf.float32, dtype_hint=None, name=None)\n\n                draft = self.__draft_image(line_128, hint_128)\n            \n                with tf.GradientTape() as tape:\n                    genOut = self.generator_512(inputs=[line, draft], training=True)\n                    loss = self.__loss(genOut, image)\n                gradients = tape.gradient(loss, self.generator_512.variables)\n                self.optimizer.apply_gradients(zip(gradients, self.generator_512.variables))\n\n                \n\n                gs = self.global_steps.numpy()\n            print (\"gen loss {}\".format(loss))\n            print(\"------------------------------SAVE_E:{}_G:{}-------------------------------------\"\n                              .format(self.epochs.numpy(), gs))\n                        \n            self.generator_512.summary()\n            print(self.global_steps)\n    \n    def save_refined(self):\n\n        save_path = \"/kaggle/working/{}_refined_30.h5\".format(self.generator_512.name)\n        self.generator_512.save(save_path, include_optimizer=False)  # for keras Model\n\n\n    def make_prediction(self, line128_img, hint128_img, line512_img):\n#         plt.imshow(hint128_img[0])\n        pred512 = self.__draft_image(line128_img, hint128_img)\n#         plt.imshow(pred512[0])\n#         cv2.imwrite('/kaggle/working/demo.jpg',np.float32(pred512[0]))\n        final_pred = self.generator_512.predict([line512_img, pred512])\n        return final_pred\n    \n    def convert_data(self, image_path, line_path):\n        \n        def fast_fetch(size, data):        \n            if (size[2]==3):\n                x=np.zeros((4,size[0],size[1],size[2]))\n                x[0] = np.asarray(data, np.float32)        \n                return x\n            elif (size[2] ==1):\n                x=np.zeros((4,size[0],size[1],size[2]))\n                x[0,:,:,0] = np.asarray(data,np.float32).reshape(size[0],size[1])\n                return x\n          \n        \n        loadData = line_to_data(image_path, line_path)\n        line128, hint128, line512 = loadData.convert_to_128()\n        line128 = tf.convert_to_tensor(fast_fetch((128,128,1), line128), dtype=tf.float32, dtype_hint=None, name=None)\n        hint128 = tf.convert_to_tensor(fast_fetch((128,128,3), hint128), dtype=tf.float32, dtype_hint=None, name=None)\n        line512 = tf.convert_to_tensor(fast_fetch((512,512,1), line512), dtype=tf.float32, dtype_hint=None, name=None)\n        prediction = self.make_prediction(line128, hint128, line512)\n        return prediction\n        \n        \n        \n# ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class line_to_data:\n    def __init__(self, image_path, line_path):\n        self.line_real_path = line_path\n        self.image_path = image_path\n        \n    def convert2float(self, img):\n        img = tf.cast(img, tf.float32)\n        img = (img / 127.5)\n        return img\n        \n    def built_hint(self, image):\n        random = np.random.rand\n        hint = np.ones_like(image)\n        hint += 1\n        leak_count = np.random.randint(16, 120)\n        if random() < 0.4:\n            leak_count = 0\n        elif random() < 0.7:\n            leak_count = np.random.randint(2, 16)\n        # leak position\n        x = np.random.randint(1, image.shape[0] - 1, leak_count)\n        y = np.random.randint(1, image.shape[1] - 1, leak_count)\n        def paintCel(i):\n            color = image[x[i]][y[i]]\n            hint[x[i]][y[i]] = color\n            if random() > 0.5:\n                hint[x[i]][y[i] + 1] = color\n                hint[x[i]][y[i] - 1] = color\n            if random() > 0.5:\n                hint[x[i] + 1][y[i]] = color\n                hint[x[i] - 1][y[i]] = color\n        for i in range(leak_count):\n            paintCel(i)\n        return hint\n        \n    def convert_to_128(self):\n        self.image = tf.io.read_file(self.image_path)\n        self.image = tf.image.decode_jpeg(self.image, channels=3)\n        self.line_real = tf.io.read_file(self.line_real_path)\n        self.line_real = tf.image.decode_jpeg(self.line_real, channels=1)\n        self.image_128 = tf.image.resize(self.image, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        self.line_128 = tf.image.resize(self.line_real, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        self.hint_128 = self.built_hint(self.image_128)\n        self.line_512 = tf.image.resize(self.line_real, (512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        self.image = self.convert2float(self.image)\n        self.line_real = self.convert2float(self.line_real)\n        self.line_128 = self.convert2float(self.line_128)\n        self.line_512 = self.convert2float(self.line_512)\n\n        return self.line_128, self.hint_128, self.line_512\n        \n\n        \n\n\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = PaintsTensorFlowTrain()\n# model.training(loadEpochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_refined()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagepath = '/kaggle/input/colorization-to-sketch-ru/real-img-test/imgreal_3188.jpeg'\nlinepath = '/kaggle/input/colorization-to-sketch-ru/sketch-img-test/img_3188.jpeg'\nprediction = model.convert_data(imagepath,linepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\n\n#subplot(r,c) provide the no. of rows and columns\nf, axarr = plt.subplots(1,3) \n\n# use the created array to output your multiple images. In this case I have stacked 4 images vertically\naxarr[0].imshow(cv2.cvtColor(cv2.imread(imagepath), cv2.COLOR_BGR2RGB))\naxarr[1].imshow(cv2.imread(linepath))\naxarr[2].imshow(prediction[0])\n# axarr[3].imshow(v_slice[3])\n\n# cv2.imwrite('/kaggle/working/real.jpeg',cv2.imread(imagepath))\n# cv2.imwrite('/kaggle/working/pred.jpeg',prediction[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(prediction[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(cv2.cvtColor(cv2.imread(imagepath), cv2.COLOR_BGR2RGB))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PaintsTensorflowDraftModel\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\ntf.compat.v1.enable_eager_execution(config=config)\nimport time\nclass PaintsTensorFlowDraftModelTrain:\n    def __init__(self, model_name=\"PaintsTensorFlowDraftModel\"):\n        self.data_sets = Datasets(batch_size=4)\n        self.model_name = model_name\n        # utils.initdir(self.model_name)\n\n        self.global_steps = tf.compat.v1.train.get_or_create_global_step()\n        self.epochs = tf.Variable(0, trainable=False, dtype=tf.int32)\n\n        self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n        self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n\n#         self.generator = Generator(name=\"PaintsTensorFlowDraftNet\")\n        self.generator = tf.keras.models.load_model(__SAVED_MODEL_PATH__)\n        \n        self.discriminator = Discriminator()\n\n    def __discriminator_loss(self, real, fake):\n        SCE = tf.nn.sigmoid_cross_entropy_with_logits\n        self.real_loss = SCE(tf.ones_like(real), logits=real)\n        self.fake_loss = SCE(tf.zeros_like(fake), logits=fake)\n        loss = self.real_loss + self.fake_loss\n        return loss\n\n    def __generator_loss(self, disOutput, output, target):\n        SCE = tf.nn.sigmoid_cross_entropy_with_logits\n        self.gan_loss = SCE(tf.ones_like(disOutput), logits=disOutput)\n        self.image_loss = tf.reduce_mean(tf.abs(target - output)) * l1_scaling\n        loss = self.image_loss + self.gan_loss\n        return loss\n\n    def __pred_image(self, model, image, line, hint, epoch=None):\n        global_steps = self.global_steps.numpy()\n        pred_image = model.predict([line, hint])\n\n        zero_hint = tf.ones_like(hint)\n        zero_hint += 1\n        pred_image_zero = model.predict([line, zero_hint])\n\n        dis_fake = self.discriminator(pred_image, training=False)\n        loss = self.__generator_loss(dis_fake, pred_image, image)\n\n#         self.__loging(\"Sample_LOSS\", loss)\n        loss = \"{:0.05f}\".format(loss).zfill(7)\n        print(\"Epoch:{} GS:{} LOSS:{}\".format(epoch, global_steps, loss))\n#         file_name = \"./ckpt/{}/image/{}_loss:{}.jpg\".format(self.model_name, global_steps, loss)\n\n        hint = np.array(hint)\n        hint[hint > 1] = 1\n\n        line_image = np.concatenate([line, line, line], -1)\n        save_img = np.concatenate([line_image, hint, pred_image_zero, pred_image, image], 1)\n        save_img = utils.convert2uint8(save_img)\n        \n    def training(self, loadEpochs=0):\n        images, lines = self.data_sets.get_image_and_line()\n        batch_steps = 750\n        def fast_fetch(size, Traindata):        \n            if (size==(4,128,128,3)):\n                x=np.zeros(size)\n                for i in range(0,4):\n                    t = Traindata[i]\n                    x[i] = np.asarray(t, np.float32)        \n                return x\n            else:\n                x=np.zeros(size)\n                for i in range(4):\n                    t = Traindata[i]\n                    x[i,:,:,0] = np.asarray(t,np.float32).reshape(128,128)\n                return x\n            \n        for epoch in range(loadEpochs):\n\n            print(\"GS: \", self.global_steps.numpy(), \"Epochs:  \", self.epochs.numpy())\n            for batch in range(batch_steps):\n                print (batch, end='\\r')\n                trainData = self.data_sets._next(images[(batch*4):(batch*4)+4], lines[(batch*4):(batch*4)+4])\n                image = tf.convert_to_tensor(fast_fetch((4,128,128,3), trainData[0]), dtype=tf.float32, dtype_hint=None, name=None)        \n                line = tf.convert_to_tensor(fast_fetch((4,128,128,1), trainData[1]), dtype=tf.float32, dtype_hint=None, name=None)\n                hint = tf.convert_to_tensor(fast_fetch((4,128,128,3), trainData[2]), dtype=tf.float32, dtype_hint=None, name=None)\n                del (trainData)\n                \n                with tf.GradientTape() as genTape, tf.GradientTape() as discTape:\n                    pred_image = self.generator(inputs=[line, hint], training=True)\n                    dis_real = self.discriminator(inputs=image, training=True)\n                    dis_fake = self.discriminator(inputs=pred_image, training=True)\n                    generator_loss = self.__generator_loss(dis_fake, pred_image, image)\n                    discriminator_loss = self.__discriminator_loss(dis_real, dis_fake)\n                discriminator_gradients = discTape.gradient(discriminator_loss, self.discriminator.variables)\n                generator_gradients = genTape.gradient(generator_loss, self.generator.variables)\n                self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.variables))\n                self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.variables))\n                gs = self.global_steps.numpy()\n                del(image)\n                del(line)\n                del(hint)\n\n            self.epochs = self.epochs + 1\n            print ('LOSS_G {}\\nLOSS_G_Image {}\\nLOSS_G_GAN {} \\nLOSS_D {}\\nLOSS_D_Real {}\\nLOSS_D_Fake {}'.format(generator_loss,self.image_loss,self.gan_loss,discriminator_loss,self.real_loss,self.fake_loss))\n        self.generator.summary()\n    def save_model(self):\n        save_path = \"/kaggle/working/{}_50.h5\".format(self.generator.name)\n        self.generator.save(save_path, include_optimizer=False)  # for keras Model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = PaintsTensorFlowDraftModelTrain()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.training(loadEpochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_model()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}